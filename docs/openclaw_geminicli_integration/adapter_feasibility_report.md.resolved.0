# アダプタ構成によるGemini CLIとOpenClawの統合可能性と限界

「OpenClawがLLMを呼ぶ際のAPIリクエスト（ツールやパラメータを含む）をローカルでGemini CLIに横流しし、APIの差異やツールの不整合を吸収するアダプタ」というアプローチについての考察です。

結論から言うと、**「動作するものは作れるが、アーキテクチャの根本的な不一致により『不可能な領域（機能低下する領域）』が存在する」**というのが実情です。

以下に、アダプタ構成が直面する3つの「構造的な限界（不可能な領域）」を解説します。

## 1. ツール（スキル）の互換性と実行主体の分離
ユーザーの提案通り、OpenClaw側からツールスキーマを送信させず、Gemini CLI側にあらかじめツールを同期させておく（あるいはMCPを利用する）ことは可能です。
しかし、**「誰がツールを実行し、誰がその結果を管理するか」**という点で大きな壁があります。

- **本来のOpenClaw**: OpenClaw本体がAPI（`@mariozechner/pi-ai`）を叩き、モデルから「ツールXを使え」と返ってきたら、**OpenClawの内部ランタイムで**スキルを実行します。これにより、OpenClawはツールの実行経過（例: 「シェルでlsを実行中...」）をリアルタイムで把握し、Telegramやログにリアルタイムストリーミングできます。
- **アダプタ構成の場合**: アダプタはリクエストを受け取った後、Gemini CLIのAgentエンジン（[GeneralistAgent](file:///home/heppo/.gemini/antigravity/playground/emerald-copernicus/gemini-cli/packages/core/src/agents/generalist-agent.ts#16-70)など）に処理を丸投げします。Gemini CLIが内部で複数回ツールを呼び出して思考を重ねた後、最終的なテキストだけをアダプタ経由でOpenClawに返します。
  - **不可能な領域**: OpenClaw側からはGemini CLIが「今何のツールを使ってどう悩んでいるか」といった中間プロセスがブラックボックス化します。経過のリアルタイムストリーミングや、OpenClaw独自の「システムイベント（例：バックグラウンドタスクの完了通知を思考に割り込ませる）」の動的注入が難しくなります。

## 2. スキルフォルダの「同期」の難しさ
OpenClawの「スキル」とGemini CLIの「ツール」は、単なるプロンプトや定義ファイルではなく、それぞれの固有のNode.jsランタイム（`OpenClawConfig` や Geminiの [Config](file:///home/heppo/.gemini/antigravity/playground/emerald-copernicus/gemini-cli/packages/core/src/agents/generalist-agent.ts#49-55), `MessageBus`）に深く依存したTypeScriptコードです。
  - **不可能な領域**: 「フォルダを同期させる」だけでは互換性がなく全く動きません。OpenClaw用に書かれたスキルをGemini CLI（またはMCPサーバー）上で動かすには、コードレベルでの「翻訳（トランスパイル）」やアダプタ層でのモックオブジェクト（仮想的な依存注入）の提供が必要になり、完全な自動同期は技術的にほぼ不可能です。

## 3. コンテキスト（会話履歴）の二重管理状態
OpenClawは `.openclaw/sessions/` に独自の形式で詳細な会話履歴（システムメタデータやHeartbeatの軌跡を含む）を管理しています。一方、Gemini CLIは `~/.gemini/` のDB・セッションファイルで状態を管理します。
アダプタがAPIリクエストを受けた際、OpenClawから送られてくる大量の「過去のメッセージ配列」をどのように扱うかが問題になります。
- 毎回Gemini CLIに全ての履歴をコンテキストとして食わせる（ステートレスAPIとして扱う）場合、Gemini CLI側の高度なセッション管理機能やReplay機能が死にます。
- 実質的に「脳」が2つある状態になり、どちらの履歴を正とすべきかの競合（Desync）が発生しやすくなります。

---

## 現状における「アダプタ」の実装方針の現実解

もし「それでもアダプタ構成で進める（完全な統合ではなく連携を優先する）」場合、以下のような設計が現実的です。

### Local MCP Gateway アプローチ
アダプタの正体を「ダミーのLLM APIサーバー」にする構成です。
1. **OpenClawの設定**: `http://localhost:8080/v1/chat/completions` を向くように設定します。
2. **アダプタの挙動**: リクエストを受け取ると、Gemini CLIの内部ライブラリ（[packages/core/src/agents/agent-scheduler.ts](file:///home/heppo/.gemini/antigravity/playground/emerald-copernicus/gemini-cli/packages/core/src/agents/agent-scheduler.ts)）をプログラムからヘッドレスで直接呼び出します（CLIプロセスとして起動するのではなく、Nodeライブラリとしてimportする）。
3. **ツールのハンドリング**: OpenClaw側には最低限のダミーツール（「あとはGeminiに任せる」という1つのツールのみ）を定義しておき、複雑な依存関係を持つ「ファイル群の編集」や「複雑な推論」などはすべてGemini CLI固有のツール群（MCPやネイティブTools）に任せます。

### 結論
アダプタ構成は実装可能ですが、「OpenClawの優れた透明性（思考過程の可視化）や、Heartbeatによる中間タスク管理」が一部犠牲（ブラックボックス化）になります。

もし**「双方のアップデートに柔軟に対応する（疎結合を保つ）」ことを最優先**とするならば、このアダプタ構成（Local API Gateway化）が最も優れた選択肢となります。機能損失は許容できる範囲でしょうか？ご意見をお聞かせください。
